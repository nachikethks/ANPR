{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as xet\n",
    "\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from shutil import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob('./test/*.xml')\n",
    "labels_dict = dict(filepath=[],xmin=[],xmax=[],ymin=[],ymax=[])\n",
    "for filename in path:\n",
    "\n",
    "    info = xet.parse(filename)\n",
    "    root = info.getroot()\n",
    "    member_object = root.find('object')\n",
    "    labels_info = member_object.find('bndbox')\n",
    "    xmin = int(labels_info.find('xmin').text)\n",
    "    xmax = int(labels_info.find('xmax').text)\n",
    "    ymin = int(labels_info.find('ymin').text)\n",
    "    ymax = int(labels_info.find('ymax').text)\n",
    "\n",
    "    labels_dict['filepath'].append(filename)\n",
    "    labels_dict['xmin'].append(xmin)\n",
    "    labels_dict['xmax'].append(xmax)\n",
    "    labels_dict['ymin'].append(ymin)\n",
    "    labels_dict['ymax'].append(ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test/Cars143.xml</td>\n",
       "      <td>93</td>\n",
       "      <td>130</td>\n",
       "      <td>196</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test/licensed_car87.xml</td>\n",
       "      <td>785</td>\n",
       "      <td>1080</td>\n",
       "      <td>651</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test/licensed_car16.xml</td>\n",
       "      <td>292</td>\n",
       "      <td>489</td>\n",
       "      <td>258</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test/Cars211.xml</td>\n",
       "      <td>28</td>\n",
       "      <td>387</td>\n",
       "      <td>64</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test/licensed_car136.xml</td>\n",
       "      <td>155</td>\n",
       "      <td>328</td>\n",
       "      <td>201</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filepath  xmin  xmax  ymin  ymax\n",
       "0          ./test/Cars143.xml    93   130   196   207\n",
       "1   ./test/licensed_car87.xml   785  1080   651   742\n",
       "2   ./test/licensed_car16.xml   292   489   258   320\n",
       "3          ./test/Cars211.xml    28   387    64   235\n",
       "4  ./test/licensed_car136.xml   155   328   201   274"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(labels_dict)\n",
    "df.to_csv('labels.csv',index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test/Cars143.xml</td>\n",
       "      <td>93</td>\n",
       "      <td>130</td>\n",
       "      <td>196</td>\n",
       "      <td>207</td>\n",
       "      <td>./test/Cars143.png</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>0.278750</td>\n",
       "      <td>0.754682</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.041199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test/licensed_car87.xml</td>\n",
       "      <td>785</td>\n",
       "      <td>1080</td>\n",
       "      <td>651</td>\n",
       "      <td>742</td>\n",
       "      <td>./test/licensed_car87.jpeg</td>\n",
       "      <td>1800</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.518056</td>\n",
       "      <td>0.580417</td>\n",
       "      <td>0.163889</td>\n",
       "      <td>0.075833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test/licensed_car16.xml</td>\n",
       "      <td>292</td>\n",
       "      <td>489</td>\n",
       "      <td>258</td>\n",
       "      <td>320</td>\n",
       "      <td>./test/licensed_car16.jpeg</td>\n",
       "      <td>769</td>\n",
       "      <td>417</td>\n",
       "      <td>0.507802</td>\n",
       "      <td>0.693046</td>\n",
       "      <td>0.256177</td>\n",
       "      <td>0.148681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test/Cars211.xml</td>\n",
       "      <td>28</td>\n",
       "      <td>387</td>\n",
       "      <td>64</td>\n",
       "      <td>235</td>\n",
       "      <td>./test/Cars211.png</td>\n",
       "      <td>400</td>\n",
       "      <td>295</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>0.506780</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.579661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test/licensed_car136.xml</td>\n",
       "      <td>155</td>\n",
       "      <td>328</td>\n",
       "      <td>201</td>\n",
       "      <td>274</td>\n",
       "      <td>./test/licensed_car136.jpeg</td>\n",
       "      <td>500</td>\n",
       "      <td>332</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.715361</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.219880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filepath  xmin  xmax  ymin  ymax  \\\n",
       "0          ./test/Cars143.xml    93   130   196   207   \n",
       "1   ./test/licensed_car87.xml   785  1080   651   742   \n",
       "2   ./test/licensed_car16.xml   292   489   258   320   \n",
       "3          ./test/Cars211.xml    28   387    64   235   \n",
       "4  ./test/licensed_car136.xml   155   328   201   274   \n",
       "\n",
       "                      filename  width  height  center_x  center_y  bb_width  \\\n",
       "0           ./test/Cars143.png    400     267  0.278750  0.754682  0.092500   \n",
       "1   ./test/licensed_car87.jpeg   1800    1200  0.518056  0.580417  0.163889   \n",
       "2   ./test/licensed_car16.jpeg    769     417  0.507802  0.693046  0.256177   \n",
       "3           ./test/Cars211.png    400     295  0.518750  0.506780  0.897500   \n",
       "4  ./test/licensed_car136.jpeg    500     332  0.483000  0.715361  0.346000   \n",
       "\n",
       "   bb_height  \n",
       "0   0.041199  \n",
       "1   0.075833  \n",
       "2   0.148681  \n",
       "3   0.579661  \n",
       "4   0.219880  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parsing(path):\n",
    "    parser = xet.parse(path).getroot()\n",
    "    name = parser.find('filename').text\n",
    "    filename = f'./test/{name}'\n",
    "    if filename[-1] != 'g':\n",
    "        filename += '.jpeg'\n",
    "\n",
    "    # width and height\n",
    "    parser_size = parser.find('size')\n",
    "    width = int(parser_size.find('width').text)\n",
    "    height = int(parser_size.find('height').text)\n",
    "    \n",
    "    return filename, width, height\n",
    "df[['filename','width','height']] = df['filepath'].apply(parsing).apply(pd.Series)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test/Cars143.xml</td>\n",
       "      <td>93</td>\n",
       "      <td>130</td>\n",
       "      <td>196</td>\n",
       "      <td>207</td>\n",
       "      <td>./test/Cars143.png</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>0.278750</td>\n",
       "      <td>0.754682</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.041199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test/licensed_car87.xml</td>\n",
       "      <td>785</td>\n",
       "      <td>1080</td>\n",
       "      <td>651</td>\n",
       "      <td>742</td>\n",
       "      <td>./test/licensed_car87.jpeg</td>\n",
       "      <td>1800</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.518056</td>\n",
       "      <td>0.580417</td>\n",
       "      <td>0.163889</td>\n",
       "      <td>0.075833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test/licensed_car16.xml</td>\n",
       "      <td>292</td>\n",
       "      <td>489</td>\n",
       "      <td>258</td>\n",
       "      <td>320</td>\n",
       "      <td>./test/licensed_car16.jpeg</td>\n",
       "      <td>769</td>\n",
       "      <td>417</td>\n",
       "      <td>0.507802</td>\n",
       "      <td>0.693046</td>\n",
       "      <td>0.256177</td>\n",
       "      <td>0.148681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test/Cars211.xml</td>\n",
       "      <td>28</td>\n",
       "      <td>387</td>\n",
       "      <td>64</td>\n",
       "      <td>235</td>\n",
       "      <td>./test/Cars211.png</td>\n",
       "      <td>400</td>\n",
       "      <td>295</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>0.506780</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.579661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test/licensed_car136.xml</td>\n",
       "      <td>155</td>\n",
       "      <td>328</td>\n",
       "      <td>201</td>\n",
       "      <td>274</td>\n",
       "      <td>./test/licensed_car136.jpeg</td>\n",
       "      <td>500</td>\n",
       "      <td>332</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.715361</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.219880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filepath  xmin  xmax  ymin  ymax  \\\n",
       "0          ./test/Cars143.xml    93   130   196   207   \n",
       "1   ./test/licensed_car87.xml   785  1080   651   742   \n",
       "2   ./test/licensed_car16.xml   292   489   258   320   \n",
       "3          ./test/Cars211.xml    28   387    64   235   \n",
       "4  ./test/licensed_car136.xml   155   328   201   274   \n",
       "\n",
       "                      filename  width  height  center_x  center_y  bb_width  \\\n",
       "0           ./test/Cars143.png    400     267  0.278750  0.754682  0.092500   \n",
       "1   ./test/licensed_car87.jpeg   1800    1200  0.518056  0.580417  0.163889   \n",
       "2   ./test/licensed_car16.jpeg    769     417  0.507802  0.693046  0.256177   \n",
       "3           ./test/Cars211.png    400     295  0.518750  0.506780  0.897500   \n",
       "4  ./test/licensed_car136.jpeg    500     332  0.483000  0.715361  0.346000   \n",
       "\n",
       "   bb_height  \n",
       "0   0.041199  \n",
       "1   0.075833  \n",
       "2   0.148681  \n",
       "3   0.579661  \n",
       "4   0.219880  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# center_x, center_y, width , height\n",
    "df['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\n",
    "df['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\n",
    "\n",
    "df['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\n",
    "df['bb_height'] = (df['ymax'] - df['ymin'])/df['height']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:500]\n",
    "df_test = df.iloc[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = './yolov5/data_images/train'\n",
    "\n",
    "values = df_train[['filename','center_x','center_y','bb_width','bb_height']].values\n",
    "for fname, x,y, w, h in values:\n",
    "    image_name = os.path.split(fname)[-1]\n",
    "    txt_name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    dst_image_path = os.path.join(train_folder,image_name)\n",
    "    dst_label_file = os.path.join(train_folder,txt_name+'.txt')\n",
    "    \n",
    "    # copy each image into the folder\n",
    "    copy(fname,dst_image_path)\n",
    "\n",
    "    # generate .txt which has label info\n",
    "    label_txt = f'0 {x} {y} {w} {h}'\n",
    "    with open(dst_label_file,mode='w') as f:\n",
    "        f.write(label_txt)\n",
    "        \n",
    "        f.close()\n",
    "\n",
    "test_folder = './yolov5/data_images/test'\n",
    "\n",
    "values = df_test[['filename','center_x','center_y','bb_width','bb_height']].values\n",
    "for fname, x,y, w, h in values:\n",
    "    image_name = os.path.split(fname)[-1]\n",
    "    txt_name = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    dst_image_path = os.path.join(test_folder,image_name)\n",
    "    dst_label_file = os.path.join(test_folder,txt_name+'.txt')\n",
    "    \n",
    "    # copy each image into the folder\n",
    "    copy(fname,dst_image_path)\n",
    "\n",
    "    # generate .txt which has label info\n",
    "    label_txt = f'0 {x} {y} {w} {h}'\n",
    "    with open(dst_label_file,mode='w') as f:\n",
    "        f.write(label_txt)\n",
    "        \n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnachiketh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=./yolov5/models/yolov5s.yaml, data=./data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "fatal: cannot change to '/home/nachiketh/MI/YOLO': No such file or directory\n",
      "YOLOv5 🚀 2022-11-26 Python-3.10.6 torch-1.13.0+cu117 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "2022-11-26 20:16:03.795001: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 20:16:04.512861: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nachiketh/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-11-26 20:16:04.512921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nachiketh/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-11-26 20:16:04.512930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/nachiketh/MI/YOLO v5/wandb/run-20221126_201605-3j8ubbe4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mModel\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nachiketh/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nachiketh/train/runs/3j8ubbe4\u001b[0m\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/nachiketh/MI/YOLO v5/yolov5/data_images/train.cache... 200\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nachiketh/MI/YOLO v5/yolov5/data_images/test.cache... 470 im\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.88 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to yolov5/runs/train/Model5/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/Model5\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/19         0G     0.1131    0.02836          0         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.300s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.300s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.300s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.300s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470     0.0087     0.0298    0.00275    0.00054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/19         0G    0.09441    0.02398          0         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470    0.00258      0.587     0.0129    0.00269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/19         0G    0.08286    0.02133          0         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470    0.00313      0.721     0.0151    0.00386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/19         0G    0.07928    0.01935          0         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.113      0.138     0.0586     0.0134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/19         0G    0.07309    0.01896          0         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470       0.18      0.636      0.357      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/19         0G    0.06528    0.01884          0          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470       0.36      0.423      0.323      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/19         0G    0.06599    0.01887          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.573      0.437      0.502      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/19         0G    0.06174    0.01943          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.549      0.531      0.569      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/19         0G    0.05722    0.01762          0         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.736       0.57      0.629      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/19         0G    0.05642    0.01774          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.806        0.6      0.715      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/19         0G     0.0528     0.0164          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.779      0.668      0.718      0.261\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/19         0G    0.05078    0.01425          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.795      0.726      0.797      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/19         0G    0.04767    0.01547          0         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.807      0.696      0.781      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/19         0G    0.04588    0.01403          0         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.822      0.768       0.82      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/19         0G    0.04459    0.01302          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.849      0.766       0.86       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/19         0G    0.04296    0.01274          0         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470       0.87      0.766      0.851      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/19         0G    0.04276     0.0124          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.888      0.755      0.862      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/19         0G    0.04173    0.01295          0         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.872      0.777      0.875        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/19         0G    0.04039    0.01345          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.864      0.811      0.885      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/19         0G    0.03895    0.01204          0         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.862      0.824      0.892      0.425\n",
      "\n",
      "20 epochs completed in 1.111 hours.\n",
      "Optimizer stripped from yolov5/runs/train/Model5/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from yolov5/runs/train/Model5/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating yolov5/runs/train/Model5/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        470        470      0.862      0.824      0.892      0.426\n",
      "Results saved to \u001b[1myolov5/runs/train/Model5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▄▄▅▅▆▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▃▃▄▄▄▅▅▆▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▂▂▄▆▅▇▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▆▇▂▆▄▅▅▆▆▇▇▇█▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▅▅▄▃▄▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▅▄▄▄▄▄▃▃▃▂▂▂▁▁▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▇▆▄▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▄▆███▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▄▆███▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.89162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.42547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.86206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.82443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.89163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.42601\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.82402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mModel\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/nachiketh/train/runs/3j8ubbe4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 297 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221126_201605-3j8ubbe4/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python3 ./yolov5/train.py --data ./data.yaml --cfg ./yolov5/models/yolov5s.yaml --batch-size 8 --name Model --epochs 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=yolov5/data/coco128.yaml, weights=['./yolov5/runs/train/Model5/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']\n",
      "fatal: cannot change to '/home/nachiketh/MI/YOLO': No such file or directory\n",
      "YOLOv5 🚀 2022-11-26 Python-3.10.6 torch-1.13.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5/runs/train/Model5/weights/best.pt with output shape (1, 25200, 6) (13.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 1.13.0+cu117...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 1.7s, saved as yolov5/runs/train/Model5/weights/best.torchscript (27.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.8s, saved as yolov5/runs/train/Model5/weights/best.onnx (27.2 MB)\n",
      "\n",
      "Export complete (3.1s)\n",
      "Results saved to \u001b[1m/home/nachiketh/MI/YOLO v5/yolov5/runs/train/Model5/weights\u001b[0m\n",
      "Detect:          python detect.py --weights yolov5/runs/train/Model5/weights/best.onnx \n",
      "Validate:        python val.py --weights yolov5/runs/train/Model5/weights/best.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5/runs/train/Model5/weights/best.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python3 ./yolov5/export.py --weight ./yolov5/runs/train/Model5/weights/best.pt --include torchscript onnx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
